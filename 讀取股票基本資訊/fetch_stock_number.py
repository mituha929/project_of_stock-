import os
import requests
from bs4 import BeautifulSoup
import csv
from concurrent.futures import ThreadPoolExecutor

def fetch_stock_data(mode, output_filename, valid_cfi_prefixes, output_dir="output"):
    # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    filepath = os.path.join(output_dir, output_filename)

    url = f"https://isin.twse.com.tw/isin/C_public.jsp?strMode={mode}"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    response.encoding = "big5-hkscs"

    stocks = []
    stock_id_list = []

    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")
        rows = soup.find_all("tr")

        for row in rows:
            cols = row.find_all("td")
            if len(cols) >= 6:
                raw = cols[0].text.strip()
                cfi_code = cols[5].text.strip()

                if any(cfi_code.startswith(prefix) for prefix in valid_cfi_prefixes):
                    cleaned = " ".join(raw.split())
                    parts = cleaned.split(" ", 1)

                    if len(parts) == 2:
                        stock_id = parts[0]
                        stock_name = parts[1]
                        listing_date = cols[2].text.strip()
                        market_type = cols[3].text.strip()
                        industry = cols[4].text.strip()

                        stocks.append([
                            stock_id,
                            stock_name,
                            listing_date,
                            market_type,
                            industry,
                        ])
                        stock_id_list.append(stock_id)

        with open(filepath, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(["è‚¡ç¥¨ä»£è™Ÿ", "è‚¡ç¥¨åç¨±", "ä¸Šå¸‚æ—¥", "å¸‚å ´åˆ¥", "ç”¢æ¥­åˆ¥"])
            writer.writerows(stocks)

        print(f"âœ… å·²æˆåŠŸå„²å­˜ {len(stocks)} ç­†è³‡æ–™è‡³ {filepath}")
    else:
        print(f"âŒ é€£ç·šå¤±æ•—ï¼šHTTP {response.status_code}ï¼Œç¶²å€ï¼š{url}")

    return stock_id_list

# åŒ…è£å‡½å¼çµ¦ ThreadPoolExecutor ä½¿ç”¨
def fetch_stock_data_thread(args):
    return fetch_stock_data(*args)

output_folder = os.path.join("data")

# ä»»å‹™æ¸…å–®ï¼šåŠ å…¥ output_dir ä½œç‚ºç¬¬ 4 å€‹åƒæ•¸
tasks = [
    (2, "list_company_number.csv", ('ESV', 'CEO', 'CMX', 'EDS', 'CBC', 'EF', 'EP'), output_folder),
    (4, "over_the_counter_number.csv", ('ESV', 'CEO', 'CMX', 'EPN'), output_folder),
    (5, "emerging_stock_market.csv", ('ESV',), output_folder),
]

# åŸ·è¡Œä»»å‹™
all_stock_ids = []
with ThreadPoolExecutor(max_workers=10) as executor:
    results = executor.map(fetch_stock_data_thread, tasks)
    for stock_ids in results:
        all_stock_ids.extend(stock_ids)

# å»é™¤é‡è¤‡ä¸¦ç¤ºç¯„å‰10ç­†
all_stock_ids = list(set(all_stock_ids))
print("ğŸ“Œ å‰10å€‹è‚¡ç¥¨ä»£è™Ÿï¼š", all_stock_ids[:10])
